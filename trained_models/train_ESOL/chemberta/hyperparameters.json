{
  "hidden_channels": 87,
  "lr": 0.0008045,
  "l2_lambda": 5e-05,
  "l1_lambda": 2.596e-05,
  "batch_size": 16,
  "dropout": 0.3408,
  "num_mlp_layers": 1,
  "epochs": 20
}